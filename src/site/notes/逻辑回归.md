---
{"dg-publish":true,"dg-path":"人工智能/机器学习/逻辑回归.md","permalink":"/人工智能/机器学习/逻辑回归/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-08-31T13:05:45.000+08:00","updated":"2025-05-23T17:18:17.000+08:00"}
---


(terminology::**Logistic Regression**)  
广义[[线性回归\|线性回归]]分析，用于分类问题，尤其是二分类问题。权重向量的[[点估计\|最大近似然估计]]
### 分类基础
分类是监督学习的最主要类型，输入变量可以是离散的，也可以是连续的
- 二分类：只需要分类1次
- 多分类：先定义其中一类为类型1（正类），其余数据为负类（rest）；接下来去掉类型1数据，剩余部分再次进行二分类。有 n 类，那就需要分类 n-1 次
### Sigmoid 函数
[[激活函数#Sigmoid\|激活函数#Sigmoid]]
Sigmoid 函数：常见的逻辑函数, S 形函数
$$\begin{align}
z=w^{T}x+b \quad \sigma (z)=g(z) =  \dfrac{1}{1+e^{-z}}\quad   g'(z)=g(z)(1-g(z))
\end{align}$$

当 $\sigma(z)\geq 0.5,y=1$ ;   当 $\sigma(z)< 0.5,y=0$ 
### 逻辑回归求解

二分类模型：$p(y\mid x;w)=(h(x))^{y}(1-h(x))^{1-y}$
逻辑函数：$z=w^{T}x+b \quad \sigma (z)=g(z) =  \dfrac{1}{1+e^{-z}}\quad   g'(z)=g(z)(1-g(z))$
损失函数： $L(\hat{y},y)=-y\log (\hat{y})-(1-y)\log(1-\hat{y})$
代价函数：$J(w)= \dfrac{1}{m} \sum\limits_{i=1}^{m}L(\hat{y},y)$


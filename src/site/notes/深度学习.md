---
{"tags":["Nonlinear"],"dg-publish":true,"dg-path":"人工智能/深度学习.md","permalink":"/人工智能/深度学习/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-05-21T15:20:28.450+08:00","updated":"2025-08-28T21:53:14.000+08:00"}
---


(terminology::**Deep Learning**)
> 深度学习是[[机器学习\|机器学习]]的重要分支，指基于**多层人工神经网络**构建的**非线性特征提取**与**模式识别**方法。

能够自动从大规模数据中学习**多层次、逐级抽象的特征表达**，显著提升了机器在图像、语音、自然语言等复杂任务中的表现。


其核心是**人工神经网络**，特别是包含多层（“深度”）隐藏层的神经网络。深度学习通过模拟人脑的神经元连接方式，从海量数据中自动学习复杂的特征表示，从而在图像识别、语音识别、自然语言处理等领域取得了突破性进展，并在许多任务中超越了传统机器学习方法。




### 一、核心概念

1.  **人工神经网络 (Artificial Neural Networks, ANNs)**:
    -   由相互连接的**神经元**（或节点）组成，这些神经元分层排列。每个连接都有一个**权重**，每个神经元有一个**偏置**和**激活函数**。

2.  **深度 (Depth)**:
    -   指神经网络中隐藏层的数量。层数越多，网络越“深”，理论上能学习到更抽象、更复杂的特征。

3.  **特征学习 (Feature Learning)**:
    -   深度学习的一个关键优势是它能够自动从原始数据中学习到有用的特征表示，而无需人工进行特征工程。

4.  **反向传播 (Backpropagation)**:
    -   训练深度神经网络的核心算法。它通过计算损失函数对网络权重的梯度，然后沿着梯度的反方向更新权重，以最小化损失。
5.  **激活函数 (Activation Function)**:
    -   引入非线性，使得神经网络能够学习非线性关系。常见的有 ReLU、Sigmoid、Tanh 等。

### 核心思想
通过**多层神经网络结构**，逐层提取数据的隐含特征。每一层输出为下一层的输入，形成**逐级抽象的特征空间**。

使用深层[[神经网络\|神经网络]]来学习复杂的数据表示。 

**神经网络的结构:** 一个典型的神经网络由以下部分组成：
1. **输入层 (Input Layer):** 接收外部输入数据。
2. **隐藏层 (Hidden Layer):** 通过一系列权重和激活函数对输入数据进行处理和转换。一个神经网络可以有一个或多个隐藏层。
3. **输出层 (Output Layer):** 生成最终的预测或分类结果。

![Pasted image 20240516120207.png](../img/user/Functional%20files/Photo%20Resources/Pasted%20image%2020240516120207.png)

学习数据高层次的抽象 Learing  Feature Representations  
表征学习，对数据的自动特征提取、自动学习和理解
自动学习数据的层次化表征
Hierarchical Representations 逐层表征抽象
End-to-End  Learning   端对端学习

### 深度学习的网络结构
[[神经网络\|神经网络]]


[[CNN\|CNN]]：卷积神经网络，特别适用于处理具有网格状拓扑的数据，如图像和视频。核心是**卷积层**和**池化层**，能够有效地捕捉局部特征并实现特征共享。  **应用**: 图像识别、目标检测、图像分割。


[[RNN\|RNN]]：循环神经网络，适用于处理序列数据，如文本、语音和时间序列。具有内部记忆，能够捕捉序列中的时间依赖性。   **应用**: 自然语言处理、语音识别、机器翻译。
 **变体**: LSTM (长短期记忆网络)、GRU (门控循环单元) 解决了传统 RNN 的梯度消失/爆炸问题。

[[LSTM\|LSTM]]：长短时记忆网络


[[Auto-Encoder\|Auto-Encoder]]：自编码器


[[GAN\|GAN]]：生成对抗网络，由一个**生成器**和一个**判别器**组成，两者相互对抗学习。生成器试图生成逼真的数据，判别器试图区分真实数据和生成数据。  **应用**: 图像生成、风格迁移、数据增强。

[[GNN\|GNN]]：图神经网络

[[Transformer\|Transformer]]：非传统递归结构，基于**自注意力机制 (Self-Attention Mechanism)**，能够并行处理序列数据，并捕捉长距离依赖。在自然语言处理领域取得了巨大成功，是 BERT、GPT 等大型语言模型的基础。





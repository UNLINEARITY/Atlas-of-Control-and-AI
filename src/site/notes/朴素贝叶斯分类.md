---
{"dg-publish":true,"dg-path":"人工智能/机器学习/朴素贝叶斯分类.md","permalink":"/人工智能/机器学习/朴素贝叶斯分类/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-11-15T16:19:25.000+08:00","updated":"2025-05-23T17:21:27.000+08:00"}
---

典型的生成学习方法：训练数据学习[[二维分布函数\|联合概率分布]]，求得后验概率分布。（概率估计方法可以是极大似然估计或贝叶斯估计）

### 贝叶斯方法
以[[贝叶斯公式\|贝叶斯公式]]为基础的分类方法
- **先验概率**  $P(Y)$：根据以往经验和分析得到的概率。在没有训练数据前假设 $Y$ 拥有的初始概率 
- **后验概率**  $P(Y\mid X)$：根据已经发生的事件来分析得到的概率。假设 $X$ 成立的情况下观察到 $Y$ 数据的概率，反映训练数据下 $Y$成立的置信度
- **联合概率**  $P(X,Y)\; P(XY)\; P(X \cap Y)$： 两个条件同时成立的概率

$$\begin{align}
P(B_{i}\mid A)&=\frac{P(AB_{i})}{P(A)} =\frac{P(B_{i})P(A\mid B_{i})}{\sum\limits_{i=1}^{n}P(A\mid B_{i})P(B_{i})}
\end{align}$$
### 朴素贝叶斯
基本假设是条件独立性，朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测

### 实际应用
拉普拉斯平滑的方法：我们为每个计数加1，因此它永远不会为零。为了平衡这一点，我们将可能单词的数量添加到除数中，因此计算结果永远不会大于1


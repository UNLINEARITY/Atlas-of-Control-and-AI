---
{"time":"2024-02-29","dg-publish":true,"dg-path":"人工智能/扩散模型.md","permalink":"/人工智能/扩散模型/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-05-21T15:20:28.000+08:00","updated":"2025-06-22T00:41:02.891+08:00"}
---

(terminology::**Diffusion Model**) 扩散模型
扩散模型或概率扩散模型是使用变分推理训练的参数化马尔可夫链，以在有限时间生成与数据匹配的样本，是生成模型领域非常重要且极具潜力的一类模型，尤其在图像生成、音频生成和时间序列建模等任务中取得了突破性的成果。

基于概率生成的强大内容生成框架，已成为图像生成与视频生成的重要技术。

### 基本概述
扩散模型（Diffusion Model）是一种通过逐步添加噪声再逐步去噪，最终生成数据的概率生成模型。它的核心思想源自非平衡热力学中的 **扩散过程（Diffusion Process）** ，本质上可以理解为对数据进行 **马尔科夫链噪声破坏（forward process）** ，再通过学习逆过程（reverse process）一步步恢复数据。

扩散模型：和其他生成模型一样，实现从噪声（采样自简单的分布）生成目标数据样本。

### 核心思想与基本流程
扩散模型主要包括两个过程：前向过程（forward process）和反向过程（reverse process），其中前向过程又称为扩散过程（diffusion process）。
#### 1. 前向扩散过程（Forward Process/Diffusion process）
目标是 **将数据逐步添加噪声，最终变成纯高斯噪声** 。
给定原始数据 $x\_0$，定义一个马尔科夫链：

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$

其中，$\beta\_t$ 是预设的噪声增加步长（通常是一个小正数，随时间步逐渐增大）。

经过 $T$ 步后，$x\_T$ 会非常接近各向同性高斯噪声。

整个前向过程可以直接写为：

$$
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
$$

其中，$\bar{\alpha} *t = \prod* {s=1}^{t} (1 - \beta\_s)$。
这个公式意味着可以直接从 $x\_0$ 采样得到 $x\_t$，避免一步步递归采样，方便训练。

#### 2. 反向去噪过程（Reverse Process）
目标是 **从噪声一步步去噪，恢复出真实数据。**
定义反向过程：
$$
p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$

模型的目标是学习这个逆过程的条件概率。
在大多数扩散模型（如 DDPM）中，简化为只预测高斯噪声：

$$
\epsilon_\theta(x_t, t) \approx \epsilon
$$

也就是说，训练模型去预测在第 $t$ 步，输入 $x\_t$ 中包含的噪声。

#### 3. 训练目标（损失函数）
最常用的损失函数是变分下界（Variational Lower Bound, VLB），但在 DDPM 中，通常优化更简单的重建噪声的均方误差（MSE）：
$$
L(\theta) = \mathbb{E}_{x_0, t, \epsilon} \left[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \right]
$$

其中：
- $\epsilon$ 是已知高斯噪声
- $\epsilon\_\theta$ 是模型预测的噪声
模型在训练时的任务就是：给你一个加了噪声的样本，预测出这个样本里的噪声。

#### 4. 采样过程（生成过程）
训练好模型后，可以从标准高斯噪声 $x\_T \sim \mathcal{N}(0, I)$ 开始，使用预测的噪声 $\epsilon\_\theta$ 反向一步步去噪，最终得到生成样本。

采样过程：

$$
x_{t-1} = \frac{1}{\sqrt{1 - \beta_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sigma_t z
$$

其中 $z \sim \mathcal{N}(0, I)$，为可选的随机噪声。

### 主流扩散模型分类
扩散模型在计算机视觉、自然语言处理等多个领域表现尤为出众，它成功解决了诸如 VAEs 的后验分布对齐问题、GANs 的不稳定性、EBMs 的计算量过大以及 NFs 的网络约束等问题，成为当今研究的热点。

| 类别                                                | 代表方法                 | 特点                  |
| ------------------------------------------------- | -------------------- | ------------------- |
| [[DDPM\|DDPM]]（Denoising Diffusion Probabilistic Model） | Ho et al., 2020      | 最经典，MSE 损失，基于 U-Net |
| DDIM（Denoising Diffusion Implicit Model）          | Song et al., 2020    | 无需随机采样，加速生成         |
| Score-based Model                                 | Song & Ermon, 2019   | 基于概率流，连接随机微分方程      |
| Latent Diffusion Model (LDM)                      | Rombach et al., 2021 | 在潜空间生成，极大加速推理       |



扩散模型在计算机视觉、自然语言处理等多个领域表现尤为出众，它成功解决了诸如 VAEs 的后验分布对齐问题、GANs 的不稳定性、EBMs 的计算量过大以及 NFs 的网络约束等问题，成为当今研究的热点。
#### 与 GAN、VAE 的对比
扩散模型解决了 GAN 的模式崩溃问题，训练非常稳定，生成质量非常高，但缺点是采样速度慢，后续研究重点是加速采样。

| 属性    | 扩散模型     | GAN    | VAE  |
| ----- | -------- | ------ | ---- |
| 训练稳定性 | 高        | 极易不稳定  | 一般稳定 |
| 样本质量  | 高        | 极高     | 中等   |
| 多样性   | 高        | 可能模式崩溃 | 高    |
| 采样速度  | 慢        | 极快     | 快    |
| 理论基础  | 变分推断，概率链 | 博弈论    | 变分推断 |

### 参考资料
https://zhuanlan.zhihu.com/p/624221952 


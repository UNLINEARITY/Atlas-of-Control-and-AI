---
{"time":"2024-02-29","dg-publish":true,"dg-path":"人工智能/扩散模型.md","permalink":"/人工智能/扩散模型/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-05-21T15:20:28.000+08:00","updated":"2025-08-30T17:48:40.796+08:00"}
---

(terminology::**Diffusion Model**) 扩散模型
> 扩散模型是一类强大的深度生成模型，它通过模拟一个“从清晰到模糊再从模糊到清晰”的过程来生成数据。因其生成质量高、训练稳定，已成为图像、音频等领域最前沿的生成技术。


扩散模型或概率扩散模型是使用变分推理训练的参数化马尔可夫链，以在有限时间生成与数据匹配的样本，是生成模型领域非常重要且极具潜力的一类模型，尤其在图像生成、音频生成和时间序列建模等任务中取得了突破性的成果。

基于概率生成的强大内容生成框架，已成为图像生成与视频生成的重要技术。


### 基本概述
扩散模型（Diffusion Model）是一种通过逐步添加噪声再逐步去噪，最终生成数据的概率生成模型。它的核心思想源自非平衡热力学中的 **扩散过程（Diffusion Process）** ，本质上可以理解为对数据进行 **马尔科夫链噪声破坏（forward process）** ，再通过学习逆过程（reverse process）一步步恢复数据。

扩散模型：和其他生成模型一样，实现从噪声（采样自简单的分布）生成目标数据样本。


### 核心思想：有序地破坏与创造

扩散模型的核心思想可以直观地理解为一个两步过程：

1.  **前向过程 (Forward Process)**: 像给一幅清晰的画反复添加微小的噪点，直到画面完全变成随机噪声。这个过程是固定的、无需学习的，它定义了数据是如何被逐渐“破坏”的。
2.  **反向过程 (Reverse Process)**: 训练一个[[神经网络\|神经网络]]来学习如何逆转上述过程。即，从一张纯噪声的图片开始，一步一步地“擦去”噪点，最终恢复出一幅清晰、真实的图像。这才是模型学习和创造的关键所在。

### 核心思想与基本流程
扩散模型主要包括两个过程：前向过程（forward process）和反向过程（reverse process），其中前向过程又称为扩散过程（diffusion process）。
#### 1. 前向过程：逐渐加噪
前向扩散过程（Forward Process/Diffusion process）

目标是 **将数据逐步添加噪声，最终变成纯高斯噪声** 。
给定原始数据 $x\_0$，定义一个马尔科夫链：

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$

其中 $\beta_t$ 是每一步添加噪声的强度。这个过程的美妙之处在于，我们可以用一个公式直接从 $x_0$ 跳到任意步 $x_t$，这极大地便利了训练。（通常是一个小正数，随时间步逐渐增大）。

经过 $T$ 步后，$x\_T$ 会非常接近各向同性高斯噪声。

整个前向过程可以直接写为：

$$
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
$$

其中，$\bar{\alpha} *t = \prod* {s=1}^{t} (1 - \beta\_s)$。
这个公式意味着可以直接从 $x\_0$ 采样得到 $x\_t$，避免一步步递归采样，方便训练。

#### 2. 反向过程：学习去噪
反向去噪过程（Reverse Process）

这是模型 $p_\theta$ 需要学习的部分。模型的目标是预测并移除在每一步中添加的噪声 $\epsilon$。因此，训练的核心任务可以简化为：


> [!important] **训练目标**
> 给定一个加噪后的样本 $x_t$ 和时间步 $t$，训练一个模型 $\epsilon_\theta(x_t, t)$ 来预测其中包含的噪声 $\epsilon$。损失函数通常是预测噪声与真实噪声之间的均方误差 (MSE)。

$$ L(\theta) = \mathbb{E}_{x_0, t, \epsilon} [ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 ] $$


目标是 **从噪声一步步去噪，恢复出真实数据。**
定义反向过程：
$$
p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$

模型的目标是学习这个逆过程的条件概率。
在大多数扩散模型（如 DDPM）中，简化为只预测高斯噪声：

$$
\epsilon_\theta(x_t, t) \approx \epsilon
$$

也就是说，训练模型去预测在第 $t$ 步，输入 $x\_t$ 中包含的噪声。

#### 3. 训练目标（损失函数）


最常用的损失函数是变分下界（Variational Lower Bound, VLB），但在 DDPM 中，通常优化更简单的重建噪声的均方误差（MSE）：
$$
L(\theta) = \mathbb{E}_{x_0, t, \epsilon} \left[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \right]
$$

其中：
- $\epsilon$ 是已知高斯噪声
- $\epsilon\_\theta$ 是模型预测的噪声
模型在训练时的任务就是：给你一个加了噪声的样本，预测出这个样本里的噪声。

#### 4.  采样：从无到有
采样过程（生成过程）

训练好模型后，可以从标准高斯噪声 $x\_T \sim \mathcal{N}(0, I)$ 开始，使用预测的噪声 $\epsilon\_\theta$ 反向一步步去噪，最终得到生成样本。

采样过程：

$$
x_{t-1} = \frac{1}{\sqrt{1 - \beta_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sigma_t z
$$

其中 $z \sim \mathcal{N}(0, I)$，为可选的随机噪声。

### 主流扩散模型分类
扩散模型在计算机视觉、自然语言处理等多个领域表现尤为出众，它成功解决了诸如 VAEs 的后验分布对齐问题、GANs 的不稳定性、EBMs 的计算量过大以及 NFs 的网络约束等问题，成为当今研究的热点。

| 类别                                                | 代表方法                 | 特点                                                                           |
| ------------------------------------------------- | -------------------- | ---------------------------------------------------------------------------- |
| [[DDPM\|DDPM]]（Denoising Diffusion Probabilistic Model） | Ho et al., 2020      | 最经典，MSE 损失，基于 U-Net                                                          |
| DDIM（Denoising Diffusion Implicit Model）          | Song et al., 2020    | 无需随机采样，加速生成                                                                  |
| Score-based Model                                 | Song & Ermon, 2019   | 基于概率流，连接随机微分方程                                                               |
| Latent Diffusion Model (LDM)                      | Rombach et al., 2021 | 在**潜空间 (Latent Space)** 中进行扩散，大幅降低计算成本，是文生图领域的里程碑。 <br>[[Stable Diffusion \|Stable Diffusion ]] |



扩散模型在计算机视觉、自然语言处理等多个领域表现尤为出众，它成功解决了诸如 VAEs 的后验分布对齐问题、GANs 的不稳定性、EBMs 的计算量过大以及 NFs 的网络约束等问题，成为当今研究的热点。
#### 与 GAN、VAE 的对比
扩散模型解决了 GAN 的模式崩溃问题，训练非常稳定，生成质量非常高，但缺点是采样速度慢，后续研究重点是加速采样。

| 属性    | 扩散模型     | GAN    | VAE  |
| ----- | -------- | ------ | ---- |
| 训练稳定性 | 高        | 极易不稳定  | 一般稳定 |
| 样本质量  | 高        | 极高     | 中等   |
| 多样性   | 高        | 可能模式崩溃 | 高    |
| 采样速度  | 慢        | 极快     | 快    |
| 理论基础  | 变分推断，概率链 | 博弈论    | 变分推断 |

### 如何控制生成内容？引导技术 (Guidance)

无条件的扩散模型只能生成随机样本。为了控制生成的内容（例如，根据文本描述生成图像），研究者们开发了**引导 (Guidance)** 技术。

- **分类器引导 (Classifier Guidance)**: 额外训练一个分类器，在去噪的每一步，利用分类器对当前生成结果的梯度来“引导”生成过程朝向期望的类别。
- **无分类器引导 (Classifier-Free Guidance, CFG)**: 目前的主流方法。在训练时，模型以一定概率接收条件（如文本描述）或不接收条件（设为空）。在推理时，将有条件预测和无条件预测的结果进行线性组合，从而在不牺牲多样性的情况下，增强生成内容与条件的一致性。这是 Stable Diffusion 等模型的关键技术。

### 参考资料
https://zhuanlan.zhihu.com/p/624221952 


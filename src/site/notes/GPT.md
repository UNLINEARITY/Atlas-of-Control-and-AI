---
{"aliases":["Generative Pre-trained Transformer"],"dg-publish":true,"dg-path":"人工智能/深度学习/GPT.md","tags":["DL","NLP"],"permalink":"/人工智能/深度学习/GPT/","dgPassFrontmatter":true,"noteIcon":"","created":"2025-04-28T13:19:15.000+08:00","updated":"2025-11-15T09:31:15.489+08:00"}
---


(terminology::**Generative Pre-trained Transformer**) 

> GPT（**G**enerative **P**re-trained **T**ransformer ）是由OpenAI开发的一系列基于 [[Transformer\|Transformer]] 架构的**预训练语言模型**。它通过在海量文本数据上进行**自回归语言建模**（即预测下一个词）的预训练，学习生成连贯、高质量的文本，是当前[[大语言模型\|大语言模型]]领域的代表性模型。

### 核心思想：单向生成与自回归
与[[BERT\|BERT]]的双向编码器不同，GPT系列模型主要使用[[Transformer\|Transformer]]的**解码器 (Decoder)** 部分。这意味着GPT模型在生成文本时，只能看到当前词语的**左侧上下文**（即前面的词语），而不能看到右侧的词语。这种**单向性**使其天然适合于**文本生成**任务。

GPT的核心思想是：
1.  **大规模预训练**: 在海量无标签文本数据上进行预训练，学习语言的统计规律和世界知识。
2.  **自回归生成**: 每次生成一个词，然后将生成的词作为新的输入，继续生成下一个词，直到生成完整的序列。

### 预训练任务：下一个词预测
GPT的预训练任务非常直接：**自回归语言建模 (Autoregressive Language Modeling)**，也称为“下一个词预测”。

-   **原理**: 给定一个文本序列的前缀，模型需要预测序列中的下一个词。例如，给定“The quick brown fox”，模型需要预测下一个词是“jumps”。
-   **作用**: 迫使模型学习到语言的语法、语义、事实知识以及文本的连贯性。

### 模型演进与涌现能力

GPT系列模型通过不断增加参数规模和训练数据量，展现出惊人的**涌现能力 (Emergent Abilities)**，即在小模型中不具备的能力，在大模型中突然出现。

-   **GPT-1 (2018)**: 1.17亿参数，首次展示了Transformer解码器在预训练+微调范式下的强大文本理解和生成能力。
-   **GPT-2 (2019)**: 15亿参数，因其生成文本的连贯性和质量而引起广泛关注，OpenAI最初选择不完全开源。
-   **GPT-3 (2020)**: 1750亿参数，是当时最大的语言模型。它在**上下文学习 (In-Context Learning)** 方面表现出色，无需微调即可通过少量示例完成多种任务。
-   **GPT-3.5 / InstructGPT (2022)**: 在GPT-3基础上，通过**指令微调 (Instruction Fine-tuning)** 和**基于人类反馈的强化学习 (RLHF)** 进行对齐，使其能够更好地遵循人类指令，生成更安全、更有帮助的回答。ChatGPT的底层模型。
-   **GPT-4 (2023)**: 进一步提升了多模态能力（接受图像输入）、推理能力和指令遵循能力，在各种专业和学术基准上表现出人类水平的性能。

### 微调与对齐

为了使预训练的GPT模型更好地服务于用户，OpenAI引入了两个关键步骤：

1.  **指令微调 (Instruction Fine-tuning)**: 使用高质量的“指令-回答”数据集对模型进行微调，使其学会理解和遵循人类的指令。
2.  **基于人类反馈的强化学习 (RLHF)**: 通过收集人类对模型输出的偏好数据，训练一个奖励模型，然后使用[[强化学习\|强化学习]]来优化GPT模型，使其生成更符合人类偏好、更安全、更无害的回答。这是ChatGPT成功的关键。

### 优缺点分析

| 优点 (Pros)                                  | 缺点 (Cons)                                                                  |
|----------------------------------------------|------------------------------------------------------------------------------|
| **强大的文本生成能力**：能够生成高质量、连贯、富有创造性的文本。 | **计算资源需求大**：预训练和推理需要巨大的计算资源。                         |
| **上下文学习 (In-Context Learning)**：通过少量示例即可完成新任务，无需微调。 | **幻觉 (Hallucination)**：可能生成看似合理但事实错误或虚构的信息。         |
| **广泛的知识储备**：通过大规模预训练，模型掌握了丰富的世界知识。 | **可控性挑战**：难以精确控制生成文本的风格、内容和事实准确性。             |
| **多模态能力**：最新版本支持图像输入。       | **推理能力有限**：在复杂逻辑推理和数学问题上仍有局限。                     |

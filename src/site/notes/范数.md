---
{"tags":["Function"],"dg-path":"A1- 数学/4. 线性代数/范数.md","dg-publish":true,"permalink":"/A1- 数学/4. 线性代数/范数/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-08-08T22:14:02.089+08:00","updated":"2025-04-17T18:49:16.668+08:00"}
---

(terminology::**Norm**)
范数是定义在[[向量空间\|向量空间]]上的一个函数，用于度量向量的大小或长度，将向量映射到非负实数。
范数属于数学和线性代数领域，特别是在优化问题、函数空间分析、机器学习中的正则化技术等方面。

### 常见的范数
**L0 范数**：即向量中非零元素的个数。
$$\|\mathbf{x}\|_0 = \text{card}(\mathbf{x})$$
**L1 范数（曼哈顿范数）**：即向量元素绝对值的和。
$$\|\mathbf{x}\|_1 = \sum_{i=1}^n |x_i|$$
**L2 范数（欧几里得范数或欧拉范数）**：即向量元素平方和的平方根。
$$\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2}$$
**L∞范数（最大范数或无穷范数）**：即向量元素绝对值的最大值。
$$\begin{align}
\|\mathbf{x}\|_\infty = \max (|x_1|, |x_2|, ..., |x_n|)
\end{align}$$

**p-范数**：当 $p$ 取不同的值时，可以得到不同的范数，如 $p=1$ 时是 L1 范数，$p=2$ 时是 L2 范数，$p \to \infty$ 时趋近于 L∞范数。
$$\|\mathbf{x}\|_p = \left (\sum_{i=1}^n |x_i|^p\right)^{1/p}$$

**Frobenius 范数**：用于度量矩阵的大小，是矩阵元素平方和的平方根。
$$\|\mathbf{A}\|_F = \sqrt{\sum_{i=1}^m \sum_{j=1}^n |a_{ij}|^2}$$

**核范数**：核范数是矩阵奇异值的和，但不包括零奇异值。
$$\|\mathbf{A}\|_* = \sum_{\lambda > 0} \lambda$$

**马氏范数**：其中 $M$ 是一个正定矩阵，马氏范数可以根据不同的 $M$ 来衡量向量的大小。
$$\|\mathbf{x}\|_M = \sqrt{\mathbf{x}^T M \mathbf{x}}$$

**切比雪夫范数**：即向量在任意维度上的绝对值的最大值。
$$\|\mathbf{x}\|_\text{Chebyshev} = \max_{i} |x_i|$$

每种范数都有其独特的性质和应用场景。例如，L1 范数可以导致稀疏解，常用于特征选择；L2 范数则常用于最小二乘问题；而核范数则在机器学习中的正则化中用来防止模型过拟合。
### 实际应用
- 在优化问题中，范数用于定义目标函数的约束条件或目标值，如L1范数可以导致稀疏解。
- 在机器学习中，范数作为正则化项，可以防止模型过拟合。
- 在信号处理中，不同类型的范数可以用于信号的重建和去噪。


